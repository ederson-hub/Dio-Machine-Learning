{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BOXEKcJrOE74-FZiHCdK2yCatGv-67m5",
      "authorship_tag": "ABX9TyMK4P9nBF9gaUTcd7wrYrhe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from PIL import Image\n",
        "from PIL import UnidentifiedImageError\n",
        "\n",
        "# 1. Definir diretórios e parâmetros\n",
        "train_dir = '/content/drive/MyDrive/_Treino_transfer/PetImages'     # Diretório de treino\n",
        "val_dir =   '/content/drive/MyDrive/_Treino_transfer/validation'    # Diretório de validação\n",
        "test_dir =  '/content/drive/MyDrive/_Treino_transfer/test'          # Diretório de teste\n",
        "img_height, img_width = 224, 224  # Dimensões das imagens\n",
        "batch_size = 32  # Tamanho do lote\n",
        "epochs = 1  # Número de épocas de treinamento\n",
        "\n",
        "# 2. Verificar existência dos diretórios\n",
        "if not os.path.exists(train_dir): raise FileNotFoundError(f\"Diretório de treino não encontrado: {train_dir}\")\n",
        "if not os.path.exists(val_dir):   raise FileNotFoundError(f\"Diretório de validação não encontrado: {val_dir}\")\n",
        "if not os.path.exists(test_dir):  raise FileNotFoundError(f\"Diretório de teste não encontrado: {test_dir}\")\n",
        "\n",
        "# Function to check if a file is a valid image\n",
        "def is_valid_image(filepath):\n",
        "    \"\"\"Checks if a file is a valid image.\"\"\"\n",
        "    try:\n",
        "        Image.open(filepath).verify()  # Attempt to open and verify the image\n",
        "        return True\n",
        "    except (IOError, SyntaxError, ValueError, UnidentifiedImageError) as e:  # Catch potential image errors including UnidentifiedImageError\n",
        "        print(f\"Error with image file: {filepath}. Error: {e}\")  # Print the error for debugging\n",
        "        return False\n",
        "\n",
        "# Function to filter out invalid image files\n",
        "def filter_invalid_images(directory):\n",
        "    \"\"\"Filters out invalid image files from a directory.\"\"\"\n",
        "    for filename in os.listdir(directory):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        # Check if it's a file before attempting to remove\n",
        "        if os.path.isfile(filepath) and not is_valid_image(filepath):\n",
        "            print(f\"Invalid image file found and removed: {filepath}\")\n",
        "            os.remove(filepath)\n",
        "\n",
        "# Filter out invalid images from train, validation, and test directories\n",
        "for root, _, files in os.walk(train_dir):\n",
        "    for file in files:\n",
        "        # Construct the full file path\n",
        "        filepath = os.path.join(root, file)\n",
        "        # Call is_valid_image directly on the file path\n",
        "        if not is_valid_image(filepath):\n",
        "            print(f\"Invalid image file found and removed: {filepath}\")\n",
        "            os.remove(filepath)\n",
        "for root, _, files in os.walk(val_dir):\n",
        "    for file in files:\n",
        "        # Construct the full file path\n",
        "        filepath = os.path.join(root, file)\n",
        "        # Call is_valid_image directly on the file path\n",
        "        if not is_valid_image(filepath):\n",
        "            print(f\"Invalid image file found and removed: {filepath}\")\n",
        "            os.remove(filepath)\n",
        "for root, _, files in os.walk(test_dir):\n",
        "    for file in files:\n",
        "        # Construct the full file path\n",
        "        filepath = os.path.join(root, file)\n",
        "        # Call is_valid_image directly on the file path\n",
        "        if not is_valid_image(filepath):\n",
        "            print(f\"Invalid image file found and removed: {filepath}\")\n",
        "            os.remove(filepath)\n",
        "\n",
        "\n",
        "# 3. Carregar modelo ResNet50 pré-treinado\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# 4. Congelar camadas iniciais\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 5. Adicionar camadas personalizadas\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(2, activation='softmax')(x)  # 2 classes: cães e gatos\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 6. Compilar modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 7. Geradores de dados\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Gerador para dados de teste\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_data = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# 8. Treinar modelo\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data\n",
        ")\n",
        "\n",
        "# 9. Avaliar modelo nos dados de teste\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# 10. Matriz de confusão e relatório de classificação\n",
        "predictions = model.predict(test_data)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "true_labels = test_data.classes\n",
        "\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "print('Matriz de Confusão:\\n', cm)\n",
        "\n",
        "cr = classification_report(true_labels, predicted_labels)\n",
        "print('Relatório de Classificação:\\n', cr)\n",
        "\n",
        "# 11. (Opcional) Salvar o modelo treinado\n",
        "model.save('/content/drive/MyDrive/_Treino_transfer/modelo_cachorro_gato.h5')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "v3IimAU9l1PY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}