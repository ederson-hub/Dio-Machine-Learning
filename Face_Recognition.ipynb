{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrmJx82BkxdYKfrcxrSREb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "33150be2"
      },
      "source": [
        "%pip install tensorflow opencv-python numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fb09051"
      },
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('data/train', exist_ok=True)\n",
        "os.makedirs('data/val', exist_ok=True)\n",
        "os.makedirs('data/test', exist_ok=True)\n",
        "os.makedirs('haarcascades', exist_ok=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "80f477e7"
      },
      "source": [
        "!wget https://github.com/opencv/opencv/raw/4.x/data/haarcascades/haarcascade_frontalface_default.xml -P haarcascades/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"yasserh/avengers-faces-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "c6GaQR49TQyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efac2c40"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def detect_faces(image_path):\n",
        "    \"\"\"\n",
        "    Detects faces in an image using the haarcascade classifier.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the input image file.\n",
        "\n",
        "    Returns:\n",
        "        A list of bounding boxes (x, y, w, h) for the detected faces.\n",
        "        Returns an empty list if no faces are detected or if there's an error\n",
        "        reading the image.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is None:\n",
        "        print(f\"Error: Could not read image from {image_path}\")\n",
        "        return []\n",
        "\n",
        "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
        "\n",
        "    if face_cascade.empty():\n",
        "        print(\"Error: Could not load face cascade classifier.\")\n",
        "        return []\n",
        "\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(\n",
        "        gray_image,\n",
        "        scaleFactor=1.1,\n",
        "        minNeighbors=5,\n",
        "        minSize=(30, 30)\n",
        "    )\n",
        "\n",
        "    return faces"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd348445"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_faces(image_path, bounding_boxes, target_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Crops, resizes, converts to grayscale, and normalizes detected faces.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the original image file.\n",
        "        bounding_boxes: A list of bounding boxes (x, y, w, h) for detected faces.\n",
        "        target_size: The desired size (width, height) for the preprocessed face images.\n",
        "\n",
        "    Returns:\n",
        "        A list of preprocessed face images as NumPy arrays, or an empty list\n",
        "        if no bounding boxes are provided or the image cannot be read.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is None:\n",
        "        print(f\"Error: Could not read image from {image_path}\")\n",
        "        return []\n",
        "\n",
        "    preprocessed_faces = []\n",
        "\n",
        "    for (x, y, w, h) in bounding_boxes:\n",
        "\n",
        "        face_crop = image[y:y+h, x:x+w]\n",
        "\n",
        "        face_resized = cv2.resize(face_crop, target_size)\n",
        "\n",
        "        face_gray = cv2.cvtColor(face_resized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        face_normalized = face_gray.astype('float32') / 255.0\n",
        "\n",
        "        preprocessed_faces.append(face_normalized)\n",
        "\n",
        "    if preprocessed_faces:\n",
        "        return np.array(preprocessed_faces)\n",
        "    else:\n",
        "        return []\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e7ceccf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92e53ca3"
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "input_shape = (128, 128, 1)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',               metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "train_dir = 'data/train'\n",
        "val_dir = 'data/val'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=32,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=32,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "QBZxgOZfMBIO"
      },
      "source": [
        "epochs = 10\n",
        "if 'train_generator' in locals() and train_generator.samples > 0:\n",
        "    num_classes = train_generator.num_classes\n",
        "    print(f\"Number of classes found by train_generator: {num_classes}\")\n",
        "\n",
        "    if model.output_shape[-1] != num_classes:\n",
        "         print(f\"Model output shape ({model.output_shape[-1]}) does not match num_classes ({num_classes}). Redefining model.\")\n",
        "         input_shape = (128, 128, 1)\n",
        "\n",
        "         model = Sequential([\n",
        "             Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "             MaxPooling2D((2, 2)),\n",
        "             Conv2D(64, (3, 3), activation='relu'),\n",
        "             MaxPooling2D((2, 2)),\n",
        "             Conv2D(128, (3, 3), activation='relu'),\n",
        "             MaxPooling2D((2, 2)),\n",
        "             Flatten(),\n",
        "             Dense(128, activation='relu'),\n",
        "             Dense(num_classes, activation='softmax')\n",
        "         ])\n",
        "\n",
        "         model.compile(optimizer=Adam(),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "         model.summary()\n",
        "else:\n",
        "    print(\"train_generator not found or has no samples. Cannot determine num_classes for model training.\")\n",
        "    steps_per_epoch = 0\n",
        "    validation_steps = 0\n",
        "    print(\"Cannot train the model: train_generator not available or empty.\")\n",
        "\n",
        "if 'train_generator' in locals() and 'val_generator' in locals() and train_generator.samples > 0 and val_generator.samples > 0:\n",
        "    steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "    validation_steps = val_generator.samples // val_generator.batch_size\n",
        "\n",
        "    if steps_per_epoch > 0 and validation_steps > 0:\n",
        "        print(\"Starting model training...\")\n",
        "        history = model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            epochs=epochs,\n",
        "            validation_data=val_generator,\n",
        "            validation_steps=validation_steps\n",
        "        )\n",
        "        print(\"Model training complete.\")\n",
        "    else:\n",
        "         print(\"Cannot train the model: Insufficient steps per epoch or validation steps.\")\n",
        "         print(f\"Training samples found: {train_generator.samples}\")\n",
        "         print(f\"Validation samples found: {val_generator.samples}\")\n",
        "         print(f\"Steps per epoch: {steps_per_epoch}\")\n",
        "         print(f\"Validation steps: {validation_steps}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8419ae42"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "\n",
        "# 2. Create ImageDataGenerator instances\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "target_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "try:\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        'data/train',\n",
        "        target_size=target_size,\n",
        "        color_mode='grayscale', # Use grayscale as per preprocessing step\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    val_generator = val_datagen.flow_from_directory(\n",
        "        'data/val',\n",
        "        target_size=target_size,\n",
        "        color_mode='grayscale', # Use grayscale as per preprocessing step\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    # Determine num_classes from the generator\n",
        "    num_classes = train_generator.num_classes\n",
        "    print(f\"Number of classes found: {num_classes}\")\n",
        "\n",
        "    if num_classes == 0:\n",
        "        print(\"No classes found in training data. Cannot build or train the model.\")\n",
        "    else:\n",
        "        # 4. Define the architecture of the neural network\n",
        "        model = Sequential([\n",
        "            Conv2D(32, (3, 3), activation='relu', input_shape=(target_size[0], target_size[1], 1)), # Grayscale input shape\n",
        "            MaxPooling2D((2, 2)),\n",
        "            Conv2D(64, (3, 3), activation='relu'),\n",
        "            MaxPooling2D((2, 2)),\n",
        "            Conv2D(128, (3, 3), activation='relu'),\n",
        "            MaxPooling2D((2, 2)),\n",
        "            Flatten(),\n",
        "            Dense(128, activation='relu'),\n",
        "            Dense(num_classes, activation='softmax') # Output layer with num_classes units\n",
        "        ])\n",
        "\n",
        "        # 5. Compile the model\n",
        "        model.compile(optimizer=Adam(),\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        # 6. Train the compiled model\n",
        "        epochs = 10 # Using a predefined epochs variable\n",
        "        # Use the generator directly, Keras will determine steps per epoch\n",
        "        # based on samples / batch_size\n",
        "        steps_per_epoch = train_generator.samples // train_generator.batch_size if train_generator.samples > 0 else None # Set to None or calculate if needed\n",
        "        validation_steps = val_generator.samples // val_generator.batch_size if val_generator.samples > 0 else None # Set to None or calculate if needed\n",
        "\n",
        "\n",
        "        # 7. Print message and train if images are found\n",
        "        if train_generator.samples > 0 and val_generator.samples > 0: # Check if samples exist\n",
        "            print(f\"Found {train_generator.samples} training images belonging to {train_generator.num_classes} classes.\")\n",
        "            print(f\"Found {val_generator.samples} validation images belonging to {val_generator.num_classes} classes.\")\n",
        "            print(\"Starting model training...\")\n",
        "            # Train the model using the generators\n",
        "            history = model.fit(\n",
        "                train_generator,\n",
        "                epochs=epochs,\n",
        "                validation_data=val_generator\n",
        "                # steps_per_epoch and validation_steps are optional when using generator directly\n",
        "                # If you want to use them, ensure they are correctly calculated or set to None\n",
        "                # as done above. Passing the generator directly is often sufficient.\n",
        "                # steps_per_epoch=steps_per_epoch, # Remove or set to None\n",
        "                # validation_steps=validation_steps # Remove or set to None\n",
        "            )\n",
        "            print(\"Model training complete.\")\n",
        "        else:\n",
        "            print(\"Cannot train the model: Insufficient images found in training or validation directories.\")\n",
        "            print(f\"Training samples found: {train_generator.samples}\")\n",
        "            print(f\"Validation samples found: {val_generator.samples}\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during data loading or model training: {e}\")\n",
        "    print(\"Please ensure 'data/train' and 'data/val' directories exist and contain image files organized into class subdirectories.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39738faa"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def recognize_faces_in_image(image_path, model, class_names):\n",
        "    \"\"\"\n",
        "    Detects faces in an image, preprocesses them, and classifies them using a trained model.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the input image file.\n",
        "        model: A trained Keras model for face classification.\n",
        "        class_names: A list or dictionary mapping class indices to class names.\n",
        "\n",
        "    Returns:\n",
        "        A list of tuples, where each tuple contains the bounding box (x, y, w, h)\n",
        "        and the predicted class name for each detected face. Returns an empty list\n",
        "        if no faces are detected or if there's an error.\n",
        "    \"\"\"\n",
        "    bounding_boxes = detect_faces(image_path)\n",
        "\n",
        "    if bounding_boxes is None or len(bounding_boxes) == 0:\n",
        "        print(f\"No faces detected in {image_path}\")\n",
        "        return []\n",
        "    if 'target_size' not in globals():\n",
        "        print(\"Error: target_size is not defined. Cannot preprocess faces.\")\n",
        "        return []\n",
        "\n",
        "    preprocessed_faces = preprocess_faces(image_path, bounding_boxes, target_size=target_size)\n",
        "\n",
        "    if not isinstance(preprocessed_faces, np.ndarray) or preprocessed_faces.size == 0:\n",
        "         print(f\"Preprocessing failed or returned empty array for faces in {image_path}\")\n",
        "         return []\n",
        "\n",
        "    if len(preprocessed_faces.shape) == 3:\n",
        "        preprocessed_faces = np.expand_dims(preprocessed_faces, axis=-1)\n",
        "\n",
        "    predictions = model.predict(preprocessed_faces)\n",
        "\n",
        "    predicted_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "    if isinstance(class_names, dict):\n",
        "        predicted_names = [class_names.get(idx, \"Unknown\") for idx in predicted_indices]\n",
        "    elif isinstance(class_names, list):\n",
        "         predicted_names = [class_names[idx] if 0 <= idx < len(class_names) else \"Unknown\" for idx in predicted_indices]\n",
        "    else:\n",
        "        print(\"Warning: class_names is not a list or dictionary. Cannot map indices to names.\")\n",
        "        predicted_names = [\"Unknown\"] * len(predicted_indices)\n",
        "\n",
        "    results = []\n",
        "    for i, (x, y, w, h) in enumerate(bounding_boxes):\n",
        "        results.append(((x, y, w, h), predicted_names[i]))\n",
        "\n",
        "    return results"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e07178dd"
      },
      "source": [
        "import cv2\n",
        "from PIL import Image as PILImage\n",
        "import numpy as np\n",
        "from IPython.display import display, Image\n",
        "import os\n",
        "import io\n",
        "\n",
        "try:\n",
        "    if 'train_generator' in locals() and hasattr(train_generator, 'class_indices'):\n",
        "         class_indices = train_generator.class_indices\n",
        "         class_names = {v: k for k, v in class_indices.items()}\n",
        "         print(\"Class names loaded successfully from train_generator for detection.\")\n",
        "    elif 'class_names' in globals() and isinstance(class_names, (list, dict)) and class_names:\n",
        "         print(\"Class names loaded successfully from global variable for detection.\")\n",
        "    else:\n",
        "         train_dir_check = 'data/train'\n",
        "         if os.path.exists(train_dir_check):\n",
        "             class_names = {i: d for i, d in enumerate(sorted(os.listdir(train_dir_check))) if os.path.isdir(os.path.join(train_dir_check, d))}\n",
        "             if class_names:\n",
        "                 print(\"Class names created from data/train directory structure for detection.\")\n",
        "             else:\n",
        "                 class_names = {}\n",
        "                 print(\"Warning: Could not determine class names from data/train directory.\")\n",
        "         else:\n",
        "            class_names = {}\n",
        "            print(\"Warning: Could not load class names. 'data/train' directory not found.\")\n",
        "\n",
        "\n",
        "    if 'model' in globals() and model is not None:\n",
        "        model_available = True\n",
        "        print(\"Model loaded successfully for detection.\")\n",
        "    else:\n",
        "        print(\"Error: Model not found. Cannot perform face recognition.\")\n",
        "        model_available = False\n",
        "\n",
        "except NameError:\n",
        "    print(\"Warning: Model or train_generator not found. Face recognition functionality will be limited.\")\n",
        "    model_available = False\n",
        "    class_names = {}\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while trying to load model/class names: {e}\")\n",
        "    model_available = False\n",
        "    class_names = {}\n",
        "\n",
        "\n",
        "def on_train_button_clicked(b):\n",
        "    with output_area:\n",
        "        output_area.clear_output()\n",
        "        print(\"Processing upload for training...\")\n",
        "\n",
        "        if not uploader.value:\n",
        "            print(\"No file uploaded.\")\n",
        "            return\n",
        "\n",
        "        uploaded_file_name = list(uploader.value.keys())[0]\n",
        "        uploaded_file_content = uploader.value[uploaded_file_name]['content']\n",
        "\n",
        "        class_name = class_name_input.value.strip()\n",
        "\n",
        "        if not class_name:\n",
        "            print(\"Please enter a class name for training.\")\n",
        "            return\n",
        "\n",
        "        save_dir = os.path.join('data', 'train', class_name)\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        save_path = os.path.join(save_dir, uploaded_file_name)\n",
        "\n",
        "        try:\n",
        "            with open(save_path, 'wb') as f:\n",
        "                f.write(uploaded_file_content)\n",
        "\n",
        "            print(f\"File '{uploaded_file_name}' saved to '{save_dir}' for training class '{class_name}'.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving file: {e}\")\n",
        "\n",
        "def on_detect_button_clicked(b):\n",
        "    with output_area:\n",
        "        output_area.clear_output()\n",
        "        print(\"Processing upload for detection...\")\n",
        "\n",
        "        if not uploader.value:\n",
        "            print(\"No file uploaded.\")\n",
        "            return\n",
        "\n",
        "        if not model_available:\n",
        "             print(\"Cannot perform face recognition: Model not available. Please train the model first.\")\n",
        "             if not class_names:\n",
        "                 print(\"Class names are also not available. Cannot proceed with recognition.\")\n",
        "             return\n",
        "        uploaded_file_name = list(uploader.value.keys())[0]\n",
        "        uploaded_file_content = uploader.value[uploaded_file_name]['content']\n",
        "        temp_image_path = f\"/tmp/uploaded_detection_image_{uploaded_file_name}\"\n",
        "        try:\n",
        "            with open(temp_image_path, 'wb') as f:\n",
        "                f.write(uploaded_file_content)\n",
        "            print(f\"Temporary file saved at {temp_image_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving temporary file: {e}\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            print(f\"Detecting and recognizing faces in {uploaded_file_name}...\")\n",
        "            if not class_names:\n",
        "                 print(\"Error: Class names are not available. Cannot perform recognition.\")\n",
        "                 return\n",
        "            global target_size\n",
        "            face_recognition_results = recognize_faces_in_image(temp_image_path, model, class_names)\n",
        "\n",
        "            if face_recognition_results:\n",
        "                print(f\"Detected and recognized {len(face_recognition_results)} faces:\")\n",
        "\n",
        "                img = cv2.imread(temp_image_path)\n",
        "\n",
        "                if img is None:\n",
        "                     print(f\"Error: Could not read image from {temp_image_path} for drawing.\")\n",
        "                else:\n",
        "                    for (x, y, w, h), name in face_recognition_results:\n",
        "                        color = (0, 255, 0)\n",
        "                        thickness = 2\n",
        "                        cv2.rectangle(img, (x, y), (x+w, y+h), color, thickness)\n",
        "\n",
        "                        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "                        font_scale = 0.7\n",
        "                        font_thickness = 2\n",
        "                        text_color = (255, 255, 255)\n",
        "                        text_position = (x, y - 10)\n",
        "\n",
        "                        if text_position[1] < 10:\n",
        "                            text_position = (x, y + h + 20)\n",
        "\n",
        "                        cv2.putText(img, name, text_position, font, font_scale, text_color, font_thickness, cv2.LINE_AA)\n",
        "\n",
        "                    result_image_path = f\"/tmp/detection_result_{uploaded_file_name}\"\n",
        "                    cv2.imwrite(result_image_path, img)\n",
        "                    print(f\"Result image saved to {result_image_path}\")\n",
        "\n",
        "                    print(\"Attempting to display detection results:\")\n",
        "                    display(Image(filename=result_image_path))\n",
        "                    print(\"Display command executed.\")\n",
        "\n",
        "            else:\n",
        "                print(\"No faces detected or recognized in the uploaded image.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during face detection/recognition: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "        finally:\n",
        "\n",
        "            if os.path.exists(temp_image_path):\n",
        "                os.remove(temp_image_path)\n",
        "                print(f\"Removed temporary file: {temp_image_path}\")\n",
        "\n",
        "train_button.on_click(on_train_button_clicked)\n",
        "detect_button.on_click(on_detect_button_clicked)\n",
        "\n",
        "print(\"Please upload an image using the widget above.\")\n",
        "print(\"If uploading for training, enter the class name before clicking 'Upload for Training'.\")\n",
        "print(\"If uploading for detection, just upload the image and click 'Detect Faces'.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acb99217"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import cv2\n",
        "\n",
        "test_data_dir = 'data/test'\n",
        "if not os.path.exists(test_data_dir) or not os.listdir(test_data_dir):\n",
        "    print(f\"Warning: Test data directory '{test_data_dir}' not found or is empty.\")\n",
        "    print(\"Please ensure test images are placed in class-specific subdirectories within this folder.\")\n",
        "    test_image_paths = []\n",
        "    true_labels = []\n",
        "else:\n",
        "    test_image_paths = []\n",
        "    true_labels = []\n",
        "    for class_name in os.listdir(test_data_dir):\n",
        "        class_dir = os.path.join(test_data_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            for image_name in os.listdir(class_dir):\n",
        "                image_path = os.path.join(class_dir, image_name)\n",
        "                if os.path.isfile(image_path):\n",
        "                    test_image_paths.append(image_path)\n",
        "                    true_labels.append(class_name)\n",
        "\n",
        "    print(f\"Found {len(test_image_paths)} test images across {len(set(true_labels))} classes.\")\n",
        "\n",
        "try:\n",
        "    if 'train_generator' in locals() and hasattr(train_generator, 'class_indices'):\n",
        "         class_indices = train_generator.class_indices\n",
        "         class_names_eval = {v: k for k, v in class_indices.items()}\n",
        "         print(\"Class names loaded from train_generator.\")\n",
        "    elif 'class_names' in globals() and isinstance(class_names, (list, dict)):\n",
        "         class_names_eval = class_names\n",
        "         print(\"Class names loaded from global variable.\")\n",
        "    else:\n",
        "         print(\"Error: Could not load class names. Cannot perform evaluation.\")\n",
        "         class_names_eval = {}\n",
        "\n",
        "    if 'model' in globals() and model is not None:\n",
        "        evaluation_model = model\n",
        "        model_available_for_eval = True\n",
        "        print(\"Model loaded successfully for evaluation.\")\n",
        "    else:\n",
        "        print(\"Error: Model not found. Cannot perform evaluation.\")\n",
        "        evaluation_model = None\n",
        "        model_available_for_eval = False\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while trying to load model/class names for evaluation: {e}\")\n",
        "    evaluation_model = None\n",
        "    class_names_eval = {}\n",
        "    model_available_for_eval = False\n",
        "\n",
        "if test_image_paths and model_available_for_eval and class_names_eval:\n",
        "    predicted_labels = []\n",
        "    actual_labels_for_predicted_faces = []\n",
        "\n",
        "    print(\"Starting evaluation...\")\n",
        "    for i, image_path in enumerate(test_image_paths):\n",
        "        true_label = os.path.basename(os.path.dirname(image_path))\n",
        "        face_recognition_results = recognize_faces_in_image(image_path, evaluation_model, class_names_eval)\n",
        "\n",
        "        if face_recognition_results:\n",
        "            if len(face_recognition_results) > 0:\n",
        "                 predicted_name = face_recognition_results[0][1]\n",
        "                 predicted_labels.append(predicted_name)\n",
        "                 actual_labels_for_predicted_faces.append(true_label)\n",
        "        else:\n",
        "            print(f\"No faces detected in {image_path}. Skipping for evaluation metrics.\")\n",
        "\n",
        "    if actual_labels_for_predicted_faces:\n",
        "        print(\"\\n--- Evaluation Results ---\")\n",
        "\n",
        "        all_labels = sorted(list(set(actual_labels_for_predicted_faces + predicted_labels)))\n",
        "        accuracy = accuracy_score(actual_labels_for_predicted_faces, predicted_labels)\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        try:\n",
        "            report = classification_report(actual_labels_for_predicted_faces, predicted_labels, labels=all_labels, zero_division=0)\n",
        "            print(\"\\nClassification Report:\")\n",
        "            print(report)\n",
        "        except ValueError as e:\n",
        "             print(f\"Could not generate classification report: {e}\")\n",
        "             print(\"This might happen if there's a mismatch in labels or insufficient samples.\")\n",
        "\n",
        "\n",
        "        print(\"\\n--- Analysis and Potential Improvements ---\")\n",
        "        print(\"Based on the accuracy and classification report:\")\n",
        "        print(\"1. Analyze the report: Look at precision, recall, and F1-score for each class.\")\n",
        "        print(\"   - Low precision for a class means the model often predicts that class incorrectly.\")\n",
        "        print(\"   - Low recall means the model often fails to detect instances of that class.\")\n",
        "        print(\"   - The F1-score is a balance between precision and recall.\")\n",
        "        print(\"2. Review False Positives and False Negatives: If possible, visually inspect images where the model made incorrect predictions.\")\n",
        "        print(\"   - False Positives: The model predicted a class, but it was incorrect.\")\n",
        "        print(\"   - False Negatives: The model failed to predict the correct class (either missed detection or wrong classification).\")\n",
        "        print(\"\\nPotential strategies for refinement and improvement:\")\n",
        "        print(\"1. Data Augmentation: Increase the diversity of the training data (e.g., more angles, lighting conditions, expressions).\")\n",
        "        print(\"2. More Training Data: A larger dataset generally leads to better generalization.\")\n",
        "        print(\"3. Hyperparameter Tuning: Experiment with learning rate, batch size, number of epochs, etc.\")\n",
        "        print(\"4. Model Architecture: Try a deeper or different CNN architecture (e.g., transfer learning with pre-trained models like VGG-Face, ResNet).\")\n",
        "        print(\"5. Face Detection Parameters: Adjust `scaleFactor`, `minNeighbors`, `minSize` in `detect_faces` to improve detection rate.\")\n",
        "        print(\"6. Preprocessing: Experiment with different preprocessing steps (e.g., histogram equalization, different normalization).\")\n",
        "        print(\"7. Loss Function: Explore different loss functions if appropriate.\")\n",
        "        print(\"8. Handle Multiple Faces: Refine the evaluation logic to correctly assess performance when multiple faces are present in an image.\")\n",
        "        print(\"9. Error Analysis: Focus on improving performance for classes with low scores.\")\n",
        "\n",
        "    else:\n",
        "        print(\"No faces were successfully processed for evaluation. Cannot calculate metrics.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nEvaluation skipped due to missing test data, model, or class names.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "debb2162"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Image\n",
        "import os\n",
        "import io\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='image/*',\n",
        "    multiple=False\n",
        ")\n",
        "\n",
        "train_button = widgets.Button(description=\"Upload for Training\")\n",
        "detect_button = widgets.Button(description=\"Detect Faces\")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "class_name_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter class name (e.g., \"John_Doe\")',\n",
        "    description='Class Name:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "upload_box = widgets.VBox([\n",
        "    widgets.Label(\"Upload an image:\"),\n",
        "    uploader,\n",
        "    class_name_input,\n",
        "    widgets.HBox([train_button, detect_button]),\n",
        "    output_area\n",
        "])\n",
        "\n",
        "display(upload_box)\n",
        "\n",
        "def on_train_button_clicked(b):\n",
        "    with output_area:\n",
        "        print(\"Train button clicked. Processing upload...\")\n",
        "\n",
        "def on_detect_button_clicked(b):\n",
        "    with output_area:\n",
        "        print(\"Detect button clicked. Processing upload...\")\n",
        "\n",
        "train_button.on_click(on_train_button_clicked)\n",
        "detect_button.on_click(on_detect_button_clicked)\n",
        "\n",
        "print(\"Please upload an image using the widget above.\")\n",
        "print(\"If uploading for training, enter the class name before clicking 'Upload for Training'.\")\n",
        "print(\"If uploading for detection, just upload the image and click 'Detect Faces'.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}